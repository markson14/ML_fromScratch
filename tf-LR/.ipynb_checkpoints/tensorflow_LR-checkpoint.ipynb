{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================]8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "\n",
      "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
      "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================]8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "def load_data(label_name='Species'):\n",
    "    \"\"\"Parses the csv file in TRAIN_URL and TEST_URL.\"\"\"\n",
    "\n",
    "    # Create a local copy of the training set.\n",
    "    train_path = tf.keras.utils.get_file(fname=TRAIN_URL.split('/')[-1],\n",
    "                                         origin=TRAIN_URL)\n",
    "    # train_path now holds the pathname: ~/.keras/datasets/iris_training.csv\n",
    "\n",
    "    # Parse the local CSV file.\n",
    "    train = pd.read_csv(filepath_or_buffer=train_path,\n",
    "                        names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                        header=0  # ignore the first row of the CSV file.\n",
    "                       )\n",
    "    # train now holds a pandas DataFrame, which is data structure\n",
    "    # analogous to a table.\n",
    "\n",
    "    # 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "    # 2. Delete (pop) the labels from the DataFrame.\n",
    "    # 3. Assign the remainder of the DataFrame to train_features\n",
    "    train_features, train_label = train, train.pop(label_name)\n",
    "\n",
    "    # Apply the preceding logic to the test set.\n",
    "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
    "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "    test_features, test_label = test, test.pop(label_name)\n",
    "\n",
    "    # Return four DataFrames.\n",
    "    return (train_features, train_label), (test_features, test_label)\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.one_hot(y_train,3)\n",
    "y_test = tf.one_hot(y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_df = pd.read_csv('datatraining.txt')\n",
    "\n",
    "# train = train_df.drop(['date'],axis=1)\n",
    "\n",
    "# label = train_df['Occupancy']\n",
    "# train = train.drop(['Occupancy'],axis=1)\n",
    "\n",
    "# x_train, x_test,y_train,y_test = train_test_split(train, label.values.reshape(-1, 1) ,random_state = 42)\n",
    "\n",
    "# # One hot coded\n",
    "# y_train = tf.concat([1 - y_train, y_train],axis=1)\n",
    "# y_test = tf.concat([1 - y_test, y_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置模型\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 1\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = x_train.shape[0]\n",
    "n_features = 4\n",
    "n_class = 3\n",
    "x = tf.placeholder(tf.float32, [None, n_features])\n",
    "y = tf.placeholder(tf.float32, [None, n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([n_features, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.00886765718460083\n",
      "Epoch: 0002 cost= 0.008709706862767537\n",
      "Epoch: 0003 cost= 0.008573962251345317\n",
      "Epoch: 0004 cost= 0.00842898984750112\n",
      "Epoch: 0005 cost= 0.008278077840805054\n",
      "Epoch: 0006 cost= 0.008125983675320943\n",
      "Epoch: 0007 cost= 0.007975981632868449\n",
      "Epoch: 0008 cost= 0.007830037673314413\n",
      "Epoch: 0009 cost= 0.007689218719800313\n",
      "Epoch: 0010 cost= 0.007554008563359579\n"
     ]
    }
   ],
   "source": [
    "# 损失函数\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred,labels=y))\n",
    "\n",
    "# 梯度下降\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# 准确率\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 初始化所有变量\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# 训练模型\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(n_samples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            _, c = sess.run([optimizer, cost], \n",
    "                            feed_dict={x: x_train[i * batch_size : (i+1) * batch_size], \n",
    "                                      y: y_train[i * batch_size : (i+1) * batch_size, :].eval()})\n",
    "            avg_cost = c / total_batch\n",
    "        plt.plot(epoch+1, avg_cost, 'co')\n",
    "\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            print(\"Epoch:\", \"%04d\" % (epoch+1), \"cost=\", avg_cost)\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    print(\"Testing Accuracy:\", accuracy.eval({x: x_train, y:y_train.eval()}))\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
